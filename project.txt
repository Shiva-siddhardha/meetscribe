Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Ran tool
Read file: client/README.md
Read file: client/package.json
Read file: server/package.json
Read file: server/server.js
Read file: server/socket.js
Read file: server/routes/summarizeRoute.js
Read file: client/src/components/VideoChat.js
Read file: client/src/components/SummaryViewer.js
Read file: client/src/components/RoomJoin.js
Read file: client/src/utils/deepgram.js
Read file: client/src/utils/vosk.js
Read file: client/src/utils/geminiApi.js
Read file: client/src/App.js
Here’s a comprehensive overview of your project, including all features, tools, technologies, APIs, and architecture:

---

## Project Overview

**Project Name:** (Implied) "ZoomText AI"  
**Type:** Real-time video meeting app with live transcription and AI-powered summarization  
**Architecture:** Full-stack (React frontend + Node.js/Express backend + WebRTC + WebSockets + AI APIs)

---

## Features

### 1. **Video Conferencing**
- **Multi-user video chat** using WebRTC (via `simple-peer`).
- **Room-based meetings:** Users join with a room code and name.
- **Mute/unmute** and **camera on/off** controls.
- **Dynamic user list:** Handles users joining/leaving in real time.

### 2. **Live Transcription**
- **Real-time speech-to-text (STT):**
  - **Deepgram API** for cloud-based, real-time transcription.
  - **Vosk (offline STT)**: Option to use in-browser speech recognition with local models (hosted in `/public/model`).
- **Per-user transcript tracking:** Each user's speech is transcribed and displayed separately.

### 3. **AI-Powered Summarization**
- **Summarize transcripts** using Google Gemini API (via backend).
- **Per-speaker and overall meeting summaries.**
- **Download summary as PDF** (using `jsPDF` and `html2pdf.js`).

### 4. **Real-Time Collaboration**
- **Socket.IO** for real-time events:
  - User join/leave notifications.
  - Transcript sharing across all users in a room.
  - WebRTC signaling for peer-to-peer video/audio.

---

## Technologies & Tools

### **Frontend (React)**
- **React 19** (with hooks)
- **Material-UI (MUI)** for UI components and styling
- **Socket.IO Client** for real-time communication
- **simple-peer** for WebRTC peer connections
- **jsPDF, html2pdf.js, file-saver** for PDF export
- **vosk-browser** for offline STT
- **Deepgram WebSocket API** for cloud STT

### **Backend (Node.js/Express)**
- **Express 5**
- **Socket.IO** for real-time signaling and events
- **CORS, dotenv** for configuration
- **Axios** for HTTP requests to external APIs
- **@deepgram/sdk** (though not directly used in the code, present in dependencies)
- **Google Gemini API** for transcript summarization (via HTTP POST)

### **Other**
- **MongoDB/Mongoose** is listed as a dependency, but not used in the current codebase (potential for future persistence).
- **Model files** for Vosk (offline STT) are included in `public/model/`.

---

## APIs & External Services

- **Deepgram API:** Used for real-time speech-to-text via WebSocket.
- **Google Gemini API:** Used for AI-powered summarization of meeting transcripts.
- **Vosk (local):** For offline/in-browser speech recognition (no external API calls).

---

## Key Components & Files

### **Frontend**
- `App.js`: Main app logic, handles joining, socket setup, and layout.
- `RoomJoin.js`: UI for joining a meeting room.
- `VideoChat.js`: Handles video/audio streams, peer connections, and user grid.
- `TranscriptPanel.js`: Displays live transcripts per user, controls for starting/stopping transcription.
- `SummaryViewer.js`: UI for summarizing transcripts, selecting speakers, and downloading summaries.
- `utils/deepgram.js`: Deepgram STT integration.
- `utils/vosk.js`: Vosk offline STT integration.
- `utils/geminiApi.js`: Calls backend for Gemini summarization.

### **Backend**
- `server.js`: Express server setup, API routes, and Socket.IO integration.
- `socket.js`: Handles all real-time events (room join, signaling, transcript, disconnect).
- `routes/summarizeRoute.js`: POST endpoint for summarizing transcripts using Gemini API.

### **Models & Static Assets**
- `public/model/`: Contains Vosk model files for offline STT (acoustic model, graph, configs, etc.).

---

## User Flow

1. **Join Meeting:** User enters a room code and name.
2. **Video Chat:** User’s camera and mic are activated; video grid is shown.
3. **Live Transcription:** User can start/stop live transcription (Deepgram or Vosk).
4. **Transcript Sharing:** Transcripts are shared in real time with all users in the room.
5. **Summarization:** Any user can request a summary (per speaker or overall) and download it as a PDF.
6. **Real-Time Updates:** All user and transcript events are synchronized via Socket.IO.

---

## Environment Variables

- `REACT_APP_DEEPGRAM_API_KEY`: Deepgram API key (frontend)
- `REACT_APP_SOCKET_URL`: Socket server URL (frontend)
- `GEMINI_API_KEY`: Google Gemini API key (backend)
- `PORT`: Server port (backend)

---

## Summary

**ZoomText AI** is a modern, full-stack web app for real-time video meetings with live, per-user transcription and AI-powered summarization. It leverages both cloud (Deepgram, Gemini) and offline (Vosk) speech technologies, provides real-time collaboration via WebRTC and Socket.IO, and offers a polished UI with Material-UI. The architecture is modular and extensible, with potential for persistent storage (MongoDB) in the future.

If you want a diagram or have questions about any specific part, let me know!